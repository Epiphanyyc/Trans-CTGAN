{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'income']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n",
      "Hype-parameter:[dropout:0.3,num_first:False,batch_first:False,num_heads:4,num_layers:1,hidden_dim:256]\n",
      "epoch!0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\ctgan\\synthesizers\\ctgan.py:1554: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.loss_values = pd.concat([self.loss_values, epoch_loss_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Generator Loss: 1.4892, Discriminator Loss: -0.1077, Corr Loss: 3.1399\n",
      "epoch!1\n",
      "Epoch 1 - Generator Loss: 1.6546, Discriminator Loss: -0.0780, Corr Loss: 3.2183\n",
      "epoch!2\n",
      "Epoch 2 - Generator Loss: 1.5789, Discriminator Loss: -0.1203, Corr Loss: 3.2246\n",
      "epoch!3\n",
      "Epoch 3 - Generator Loss: 1.5538, Discriminator Loss: -0.1038, Corr Loss: 2.9463\n",
      "epoch!4\n",
      "Epoch 4 - Generator Loss: 1.6074, Discriminator Loss: -0.1380, Corr Loss: 3.2571\n",
      "epoch!5\n",
      "Epoch 5 - Generator Loss: 1.4865, Discriminator Loss: -0.1327, Corr Loss: 2.9048\n",
      "epoch!6\n",
      "Epoch 6 - Generator Loss: 1.3882, Discriminator Loss: -0.1260, Corr Loss: 2.9276\n",
      "epoch!7\n",
      "Epoch 7 - Generator Loss: 1.4277, Discriminator Loss: -0.1026, Corr Loss: 3.2912\n",
      "epoch!8\n",
      "Epoch 8 - Generator Loss: 1.2902, Discriminator Loss: -0.1246, Corr Loss: 3.1161\n",
      "epoch!9\n",
      "Epoch 9 - Generator Loss: 1.1434, Discriminator Loss: -0.1470, Corr Loss: 3.3181\n",
      "epoch!10\n",
      "Epoch 10 - Generator Loss: 1.1466, Discriminator Loss: -0.1642, Corr Loss: 3.1309\n",
      "epoch!11\n",
      "Epoch 11 - Generator Loss: 1.0805, Discriminator Loss: -0.1105, Corr Loss: 3.4552\n",
      "epoch!12\n",
      "Epoch 12 - Generator Loss: 1.1208, Discriminator Loss: -0.1499, Corr Loss: 3.2943\n",
      "epoch!13\n",
      "Epoch 13 - Generator Loss: 0.8327, Discriminator Loss: -0.1588, Corr Loss: 2.9384\n",
      "epoch!14\n",
      "Epoch 14 - Generator Loss: 0.8697, Discriminator Loss: -0.1585, Corr Loss: 3.5884\n",
      "epoch!15\n",
      "Epoch 15 - Generator Loss: 0.6901, Discriminator Loss: -0.1216, Corr Loss: 3.5621\n",
      "epoch!16\n",
      "Epoch 16 - Generator Loss: 0.5872, Discriminator Loss: -0.1185, Corr Loss: 4.0337\n",
      "epoch!17\n",
      "Epoch 17 - Generator Loss: 0.3435, Discriminator Loss: -0.0937, Corr Loss: 3.9831\n",
      "epoch!18\n",
      "Epoch 18 - Generator Loss: 0.3406, Discriminator Loss: -0.1715, Corr Loss: 3.8821\n",
      "epoch!19\n",
      "Epoch 19 - Generator Loss: 0.2389, Discriminator Loss: -0.1526, Corr Loss: 4.2296\n",
      "epoch!20\n",
      "Epoch 20 - Generator Loss: 0.2465, Discriminator Loss: -0.1213, Corr Loss: 4.6619\n",
      "epoch!21\n",
      "Epoch 21 - Generator Loss: 0.2462, Discriminator Loss: -0.1443, Corr Loss: 5.5316\n",
      "epoch!22\n",
      "Epoch 22 - Generator Loss: 0.1252, Discriminator Loss: -0.1514, Corr Loss: 4.9746\n",
      "epoch!23\n",
      "Epoch 23 - Generator Loss: 0.1330, Discriminator Loss: -0.1509, Corr Loss: 4.6733\n",
      "epoch!24\n",
      "Epoch 24 - Generator Loss: 0.0903, Discriminator Loss: -0.1468, Corr Loss: 4.2093\n",
      "epoch!25\n",
      "Epoch 25 - Generator Loss: -0.0054, Discriminator Loss: -0.1369, Corr Loss: 4.6204\n",
      "epoch!26\n",
      "Epoch 26 - Generator Loss: 0.0388, Discriminator Loss: -0.1129, Corr Loss: 4.7045\n",
      "epoch!27\n",
      "Epoch 27 - Generator Loss: 0.0224, Discriminator Loss: -0.1162, Corr Loss: 4.7905\n",
      "epoch!28\n",
      "Epoch 28 - Generator Loss: 0.0160, Discriminator Loss: -0.1299, Corr Loss: 4.4970\n",
      "epoch!29\n",
      "Epoch 29 - Generator Loss: 0.0077, Discriminator Loss: -0.1396, Corr Loss: 4.5570\n",
      "epoch!30\n",
      "Epoch 30 - Generator Loss: 0.0142, Discriminator Loss: -0.1049, Corr Loss: 4.7751\n",
      "epoch!31\n",
      "Epoch 31 - Generator Loss: 0.0199, Discriminator Loss: -0.1291, Corr Loss: 4.6988\n",
      "epoch!32\n",
      "Epoch 32 - Generator Loss: 0.0137, Discriminator Loss: -0.1315, Corr Loss: 4.6697\n",
      "epoch!33\n",
      "Epoch 33 - Generator Loss: 0.0476, Discriminator Loss: -0.1607, Corr Loss: 4.7616\n",
      "epoch!34\n",
      "Epoch 34 - Generator Loss: 0.0015, Discriminator Loss: -0.1115, Corr Loss: 4.8807\n",
      "epoch!35\n",
      "Epoch 35 - Generator Loss: 0.0436, Discriminator Loss: -0.1603, Corr Loss: 5.0165\n",
      "epoch!36\n",
      "Epoch 36 - Generator Loss: -0.0137, Discriminator Loss: -0.1473, Corr Loss: 4.4989\n",
      "epoch!37\n",
      "Epoch 37 - Generator Loss: -0.0250, Discriminator Loss: -0.1207, Corr Loss: 4.4603\n",
      "epoch!38\n",
      "Epoch 38 - Generator Loss: -0.0116, Discriminator Loss: -0.1413, Corr Loss: 4.6761\n",
      "epoch!39\n",
      "Epoch 39 - Generator Loss: -0.0377, Discriminator Loss: -0.1456, Corr Loss: 4.7785\n",
      "epoch!40\n",
      "Epoch 40 - Generator Loss: -0.0607, Discriminator Loss: -0.1419, Corr Loss: 4.3243\n",
      "epoch!41\n",
      "Epoch 41 - Generator Loss: -0.0269, Discriminator Loss: -0.1302, Corr Loss: 4.6407\n",
      "epoch!42\n",
      "Epoch 42 - Generator Loss: -0.0125, Discriminator Loss: -0.1274, Corr Loss: 5.0037\n",
      "epoch!43\n",
      "Epoch 43 - Generator Loss: -0.0199, Discriminator Loss: -0.1124, Corr Loss: 4.7927\n",
      "epoch!44\n",
      "Epoch 44 - Generator Loss: -0.0104, Discriminator Loss: -0.1250, Corr Loss: 4.5349\n",
      "epoch!45\n",
      "Epoch 45 - Generator Loss: -0.0474, Discriminator Loss: -0.1321, Corr Loss: 4.5653\n",
      "epoch!46\n",
      "Epoch 46 - Generator Loss: -0.0391, Discriminator Loss: -0.1177, Corr Loss: 4.5970\n",
      "epoch!47\n",
      "Epoch 47 - Generator Loss: -0.0580, Discriminator Loss: -0.1541, Corr Loss: 4.6247\n",
      "epoch!48\n",
      "Epoch 48 - Generator Loss: -0.0653, Discriminator Loss: -0.1543, Corr Loss: 4.8241\n",
      "epoch!49\n",
      "Epoch 49 - Generator Loss: -0.0646, Discriminator Loss: -0.0925, Corr Loss: 4.8133\n",
      "epoch!50\n",
      "Epoch 50 - Generator Loss: -0.0294, Discriminator Loss: -0.1341, Corr Loss: 4.3454\n",
      "epoch!51\n",
      "Epoch 51 - Generator Loss: -0.0321, Discriminator Loss: -0.1351, Corr Loss: 4.9492\n",
      "epoch!52\n",
      "Epoch 52 - Generator Loss: -0.1030, Discriminator Loss: -0.1069, Corr Loss: 4.2252\n",
      "epoch!53\n",
      "Epoch 53 - Generator Loss: -0.0949, Discriminator Loss: -0.0993, Corr Loss: 4.4212\n",
      "epoch!54\n",
      "Epoch 54 - Generator Loss: -0.0936, Discriminator Loss: -0.1292, Corr Loss: 4.2808\n",
      "epoch!55\n",
      "Epoch 55 - Generator Loss: -0.0917, Discriminator Loss: -0.1274, Corr Loss: 4.2886\n",
      "epoch!56\n",
      "Epoch 56 - Generator Loss: -0.0668, Discriminator Loss: -0.1412, Corr Loss: 4.7145\n",
      "epoch!57\n",
      "Epoch 57 - Generator Loss: -0.0914, Discriminator Loss: -0.1295, Corr Loss: 4.8521\n",
      "epoch!58\n",
      "Epoch 58 - Generator Loss: -0.0775, Discriminator Loss: -0.1205, Corr Loss: 4.2728\n",
      "epoch!59\n",
      "Epoch 59 - Generator Loss: -0.0656, Discriminator Loss: -0.1254, Corr Loss: 4.7046\n",
      "epoch!60\n",
      "Epoch 60 - Generator Loss: -0.1090, Discriminator Loss: -0.1413, Corr Loss: 4.7942\n",
      "epoch!61\n",
      "Epoch 61 - Generator Loss: -0.0847, Discriminator Loss: -0.1300, Corr Loss: 4.6036\n",
      "epoch!62\n",
      "Epoch 62 - Generator Loss: -0.1334, Discriminator Loss: -0.1085, Corr Loss: 4.3825\n",
      "epoch!63\n",
      "Epoch 63 - Generator Loss: -0.0582, Discriminator Loss: -0.1633, Corr Loss: 4.6071\n",
      "epoch!64\n",
      "Epoch 64 - Generator Loss: -0.1305, Discriminator Loss: -0.1185, Corr Loss: 4.5085\n",
      "epoch!65\n",
      "Epoch 65 - Generator Loss: -0.1003, Discriminator Loss: -0.1923, Corr Loss: 4.6336\n",
      "epoch!66\n",
      "Epoch 66 - Generator Loss: -0.1904, Discriminator Loss: -0.0233, Corr Loss: 4.4792\n",
      "epoch!67\n",
      "Epoch 67 - Generator Loss: -0.1048, Discriminator Loss: -0.0772, Corr Loss: 4.6552\n",
      "epoch!68\n",
      "Epoch 68 - Generator Loss: -0.0329, Discriminator Loss: -0.1784, Corr Loss: 4.5154\n",
      "epoch!69\n",
      "Epoch 69 - Generator Loss: -0.0747, Discriminator Loss: -0.1272, Corr Loss: 4.8314\n",
      "epoch!70\n",
      "Epoch 70 - Generator Loss: -0.0995, Discriminator Loss: -0.0895, Corr Loss: 5.1727\n",
      "epoch!71\n",
      "Epoch 71 - Generator Loss: -0.1380, Discriminator Loss: -0.1044, Corr Loss: 4.3392\n",
      "epoch!72\n",
      "Epoch 72 - Generator Loss: -0.2010, Discriminator Loss: -0.0605, Corr Loss: 3.9145\n",
      "epoch!73\n",
      "Epoch 73 - Generator Loss: -0.1951, Discriminator Loss: -0.0921, Corr Loss: 3.8831\n",
      "epoch!74\n",
      "Epoch 74 - Generator Loss: -0.1741, Discriminator Loss: -0.0859, Corr Loss: 4.0753\n",
      "epoch!75\n",
      "Epoch 75 - Generator Loss: -0.1164, Discriminator Loss: -0.1015, Corr Loss: 4.5969\n",
      "epoch!76\n",
      "Epoch 76 - Generator Loss: -0.1574, Discriminator Loss: -0.1183, Corr Loss: 4.0975\n",
      "epoch!77\n",
      "Epoch 77 - Generator Loss: -0.1520, Discriminator Loss: -0.1042, Corr Loss: 4.1407\n",
      "epoch!78\n",
      "Epoch 78 - Generator Loss: -0.1887, Discriminator Loss: -0.1046, Corr Loss: 4.3137\n",
      "epoch!79\n",
      "Epoch 79 - Generator Loss: -0.1949, Discriminator Loss: -0.1371, Corr Loss: 4.1708\n",
      "epoch!80\n",
      "Epoch 80 - Generator Loss: -0.2737, Discriminator Loss: -0.1140, Corr Loss: 4.3775\n",
      "epoch!81\n",
      "Epoch 81 - Generator Loss: -0.2216, Discriminator Loss: -0.0920, Corr Loss: 3.7911\n",
      "epoch!82\n",
      "Epoch 82 - Generator Loss: -0.1748, Discriminator Loss: -0.1110, Corr Loss: 4.3598\n",
      "epoch!83\n",
      "Epoch 83 - Generator Loss: -0.1862, Discriminator Loss: -0.0881, Corr Loss: 4.3898\n",
      "epoch!84\n",
      "Epoch 84 - Generator Loss: -0.1992, Discriminator Loss: -0.0975, Corr Loss: 3.9906\n",
      "epoch!85\n",
      "Epoch 85 - Generator Loss: -0.2144, Discriminator Loss: -0.0731, Corr Loss: 3.8021\n",
      "epoch!86\n",
      "Epoch 86 - Generator Loss: -0.1702, Discriminator Loss: -0.1325, Corr Loss: 4.4819\n",
      "epoch!87\n",
      "Epoch 87 - Generator Loss: -0.2407, Discriminator Loss: -0.0691, Corr Loss: 3.9698\n",
      "epoch!88\n",
      "Epoch 88 - Generator Loss: -0.1974, Discriminator Loss: -0.1001, Corr Loss: 4.2490\n",
      "epoch!89\n",
      "Epoch 89 - Generator Loss: -0.2154, Discriminator Loss: -0.1030, Corr Loss: 4.1927\n",
      "epoch!90\n",
      "Epoch 90 - Generator Loss: -0.1802, Discriminator Loss: -0.1236, Corr Loss: 4.1947\n",
      "epoch!91\n",
      "Epoch 91 - Generator Loss: -0.1928, Discriminator Loss: -0.0931, Corr Loss: 4.1704\n",
      "epoch!92\n",
      "Epoch 92 - Generator Loss: -0.1961, Discriminator Loss: -0.1207, Corr Loss: 3.7749\n",
      "epoch!93\n",
      "Epoch 93 - Generator Loss: -0.2499, Discriminator Loss: -0.0993, Corr Loss: 4.1115\n",
      "epoch!94\n",
      "Epoch 94 - Generator Loss: -0.2440, Discriminator Loss: -0.0872, Corr Loss: 3.7768\n",
      "epoch!95\n",
      "Epoch 95 - Generator Loss: -0.2544, Discriminator Loss: -0.0723, Corr Loss: 3.9930\n",
      "epoch!96\n",
      "Epoch 96 - Generator Loss: -0.2759, Discriminator Loss: -0.0865, Corr Loss: 3.9129\n",
      "epoch!97\n",
      "Epoch 97 - Generator Loss: -0.2579, Discriminator Loss: -0.1039, Corr Loss: 3.7589\n",
      "epoch!98\n",
      "Epoch 98 - Generator Loss: -0.2941, Discriminator Loss: -0.0997, Corr Loss: 3.7334\n",
      "epoch!99\n",
      "Epoch 99 - Generator Loss: -0.2631, Discriminator Loss: -0.0968, Corr Loss: 4.0158\n",
      "epoch!100\n",
      "Epoch 100 - Generator Loss: -0.2529, Discriminator Loss: -0.1104, Corr Loss: 3.8444\n",
      "epoch!101\n",
      "Epoch 101 - Generator Loss: -0.2762, Discriminator Loss: -0.0950, Corr Loss: 3.7908\n",
      "epoch!102\n",
      "Epoch 102 - Generator Loss: -0.3056, Discriminator Loss: -0.1015, Corr Loss: 3.5581\n",
      "epoch!103\n",
      "Epoch 103 - Generator Loss: -0.2926, Discriminator Loss: -0.0975, Corr Loss: 3.6298\n",
      "epoch!104\n",
      "Epoch 104 - Generator Loss: -0.2808, Discriminator Loss: -0.0981, Corr Loss: 3.7344\n",
      "epoch!105\n",
      "Epoch 105 - Generator Loss: -0.2659, Discriminator Loss: -0.0950, Corr Loss: 3.6969\n",
      "epoch!106\n",
      "Epoch 106 - Generator Loss: -0.2996, Discriminator Loss: -0.1008, Corr Loss: 3.6712\n",
      "epoch!107\n",
      "Epoch 107 - Generator Loss: -0.3076, Discriminator Loss: -0.1019, Corr Loss: 3.6659\n",
      "epoch!108\n",
      "Epoch 108 - Generator Loss: -0.2983, Discriminator Loss: -0.0955, Corr Loss: 3.6333\n",
      "epoch!109\n",
      "Epoch 109 - Generator Loss: -0.3089, Discriminator Loss: -0.0915, Corr Loss: 3.5622\n",
      "epoch!110\n",
      "Epoch 110 - Generator Loss: -0.3506, Discriminator Loss: -0.0849, Corr Loss: 3.3939\n",
      "epoch!111\n",
      "Epoch 111 - Generator Loss: -0.3113, Discriminator Loss: -0.0881, Corr Loss: 3.5426\n",
      "epoch!112\n",
      "Epoch 112 - Generator Loss: -0.3097, Discriminator Loss: -0.0905, Corr Loss: 3.6591\n",
      "epoch!113\n",
      "Epoch 113 - Generator Loss: -0.3202, Discriminator Loss: -0.0804, Corr Loss: 3.7757\n",
      "epoch!114\n",
      "Epoch 114 - Generator Loss: -0.3276, Discriminator Loss: -0.1108, Corr Loss: 3.6679\n",
      "epoch!115\n",
      "Epoch 115 - Generator Loss: -0.3042, Discriminator Loss: -0.0952, Corr Loss: 3.8501\n",
      "epoch!116\n",
      "Epoch 116 - Generator Loss: -0.3233, Discriminator Loss: -0.0713, Corr Loss: 3.5246\n",
      "epoch!117\n",
      "Epoch 117 - Generator Loss: -0.3097, Discriminator Loss: -0.0971, Corr Loss: 3.7711\n",
      "epoch!118\n",
      "Epoch 118 - Generator Loss: -0.3106, Discriminator Loss: -0.0929, Corr Loss: 3.6635\n",
      "epoch!119\n",
      "Epoch 119 - Generator Loss: -0.3208, Discriminator Loss: -0.1071, Corr Loss: 3.3562\n",
      "epoch!120\n",
      "Epoch 120 - Generator Loss: -0.3226, Discriminator Loss: -0.0811, Corr Loss: 3.5292\n",
      "epoch!121\n",
      "Epoch 121 - Generator Loss: -0.3312, Discriminator Loss: -0.0925, Corr Loss: 3.6002\n",
      "epoch!122\n",
      "Epoch 122 - Generator Loss: -0.3458, Discriminator Loss: -0.0958, Corr Loss: 3.5621\n",
      "epoch!123\n",
      "Epoch 123 - Generator Loss: -0.3101, Discriminator Loss: -0.1019, Corr Loss: 3.6786\n",
      "epoch!124\n",
      "Epoch 124 - Generator Loss: -0.3275, Discriminator Loss: -0.0906, Corr Loss: 3.8880\n",
      "epoch!125\n",
      "Epoch 125 - Generator Loss: -0.3281, Discriminator Loss: -0.1001, Corr Loss: 3.3228\n",
      "epoch!126\n",
      "Epoch 126 - Generator Loss: -0.3171, Discriminator Loss: -0.0939, Corr Loss: 3.6127\n",
      "epoch!127\n",
      "Epoch 127 - Generator Loss: -0.3256, Discriminator Loss: -0.0958, Corr Loss: 3.8419\n",
      "epoch!128\n",
      "Epoch 128 - Generator Loss: -0.3565, Discriminator Loss: -0.0926, Corr Loss: 3.4044\n",
      "epoch!129\n",
      "Epoch 129 - Generator Loss: -0.3307, Discriminator Loss: -0.0844, Corr Loss: 3.6840\n",
      "epoch!130\n",
      "Epoch 130 - Generator Loss: -0.3511, Discriminator Loss: -0.1001, Corr Loss: 3.7533\n",
      "epoch!131\n",
      "Epoch 131 - Generator Loss: -0.3351, Discriminator Loss: -0.0801, Corr Loss: 3.6417\n",
      "epoch!132\n",
      "Epoch 132 - Generator Loss: -0.3141, Discriminator Loss: -0.0980, Corr Loss: 3.7387\n",
      "epoch!133\n",
      "Epoch 133 - Generator Loss: -0.3709, Discriminator Loss: -0.0853, Corr Loss: 3.5702\n",
      "epoch!134\n",
      "Epoch 134 - Generator Loss: -0.3555, Discriminator Loss: -0.0797, Corr Loss: 3.5005\n",
      "epoch!135\n",
      "Epoch 135 - Generator Loss: -0.3607, Discriminator Loss: -0.0739, Corr Loss: 3.5604\n",
      "epoch!136\n",
      "Epoch 136 - Generator Loss: -0.3542, Discriminator Loss: -0.0793, Corr Loss: 3.9646\n",
      "epoch!137\n",
      "Epoch 137 - Generator Loss: -0.3744, Discriminator Loss: -0.0839, Corr Loss: 3.7133\n",
      "epoch!138\n",
      "Epoch 138 - Generator Loss: -0.3508, Discriminator Loss: -0.0749, Corr Loss: 3.7968\n",
      "epoch!139\n",
      "Epoch 139 - Generator Loss: -0.3629, Discriminator Loss: -0.0792, Corr Loss: 3.9781\n",
      "epoch!140\n",
      "Epoch 140 - Generator Loss: -0.3204, Discriminator Loss: -0.0853, Corr Loss: 4.2425\n",
      "epoch!141\n",
      "Epoch 141 - Generator Loss: -0.3376, Discriminator Loss: -0.0867, Corr Loss: 3.2841\n",
      "epoch!142\n",
      "Epoch 142 - Generator Loss: -0.3908, Discriminator Loss: -0.0794, Corr Loss: 3.4471\n",
      "epoch!143\n",
      "Epoch 143 - Generator Loss: -0.3643, Discriminator Loss: -0.0793, Corr Loss: 3.6213\n",
      "epoch!144\n",
      "Epoch 144 - Generator Loss: -0.3682, Discriminator Loss: -0.0831, Corr Loss: 3.4732\n",
      "epoch!145\n",
      "Epoch 145 - Generator Loss: -0.3794, Discriminator Loss: -0.0684, Corr Loss: 3.9217\n",
      "epoch!146\n",
      "Epoch 146 - Generator Loss: -0.3755, Discriminator Loss: -0.0992, Corr Loss: 3.6444\n",
      "epoch!147\n",
      "Epoch 147 - Generator Loss: -0.3703, Discriminator Loss: -0.0766, Corr Loss: 3.8568\n",
      "epoch!148\n",
      "Epoch 148 - Generator Loss: -0.4025, Discriminator Loss: -0.0690, Corr Loss: 3.4503\n",
      "epoch!149\n",
      "Epoch 149 - Generator Loss: -0.3933, Discriminator Loss: -0.0743, Corr Loss: 3.7753\n",
      "epoch!150\n",
      "Epoch 150 - Generator Loss: -0.3623, Discriminator Loss: -0.0899, Corr Loss: 3.6691\n",
      "epoch!151\n",
      "Epoch 151 - Generator Loss: -0.3146, Discriminator Loss: -0.0703, Corr Loss: 3.9067\n",
      "epoch!152\n",
      "Epoch 152 - Generator Loss: -0.3938, Discriminator Loss: -0.0781, Corr Loss: 3.7216\n",
      "epoch!153\n",
      "Epoch 153 - Generator Loss: -0.3966, Discriminator Loss: -0.0708, Corr Loss: 3.7545\n",
      "epoch!154\n",
      "Epoch 154 - Generator Loss: -0.4459, Discriminator Loss: -0.0746, Corr Loss: 3.8745\n",
      "epoch!155\n",
      "Epoch 155 - Generator Loss: -0.4009, Discriminator Loss: -0.0762, Corr Loss: 3.7678\n",
      "epoch!156\n",
      "Epoch 156 - Generator Loss: -0.4306, Discriminator Loss: -0.0787, Corr Loss: 3.8082\n",
      "epoch!157\n",
      "Epoch 157 - Generator Loss: -0.3967, Discriminator Loss: -0.0721, Corr Loss: 3.7340\n",
      "epoch!158\n",
      "Epoch 158 - Generator Loss: -0.5087, Discriminator Loss: -0.0720, Corr Loss: 3.5575\n",
      "epoch!159\n",
      "Epoch 159 - Generator Loss: -0.4023, Discriminator Loss: -0.0860, Corr Loss: 3.7041\n",
      "epoch!160\n",
      "Epoch 160 - Generator Loss: -0.4154, Discriminator Loss: -0.0705, Corr Loss: 3.7307\n",
      "epoch!161\n",
      "Epoch 161 - Generator Loss: -0.3885, Discriminator Loss: -0.0840, Corr Loss: 3.7211\n",
      "epoch!162\n",
      "Epoch 162 - Generator Loss: -0.4157, Discriminator Loss: -0.0868, Corr Loss: 3.9936\n",
      "epoch!163\n",
      "Epoch 163 - Generator Loss: -0.3955, Discriminator Loss: -0.0859, Corr Loss: 3.6661\n",
      "epoch!164\n",
      "Epoch 164 - Generator Loss: -0.4276, Discriminator Loss: -0.0792, Corr Loss: 3.5210\n",
      "epoch!165\n",
      "Epoch 165 - Generator Loss: -0.4137, Discriminator Loss: -0.0754, Corr Loss: 3.4734\n",
      "epoch!166\n",
      "Epoch 166 - Generator Loss: -0.4069, Discriminator Loss: -0.0629, Corr Loss: 3.6640\n",
      "epoch!167\n",
      "Epoch 167 - Generator Loss: -0.4287, Discriminator Loss: -0.0650, Corr Loss: 3.2292\n",
      "epoch!168\n",
      "Epoch 168 - Generator Loss: -0.4050, Discriminator Loss: -0.0758, Corr Loss: 3.3385\n",
      "epoch!169\n",
      "Epoch 169 - Generator Loss: -0.4206, Discriminator Loss: -0.0698, Corr Loss: 3.5599\n",
      "epoch!170\n",
      "Epoch 170 - Generator Loss: -0.4403, Discriminator Loss: -0.0699, Corr Loss: 3.5716\n",
      "epoch!171\n",
      "Epoch 171 - Generator Loss: -0.4188, Discriminator Loss: -0.0877, Corr Loss: 3.3617\n",
      "epoch!172\n",
      "Epoch 172 - Generator Loss: -0.4457, Discriminator Loss: -0.0727, Corr Loss: 3.6713\n",
      "epoch!173\n",
      "Epoch 173 - Generator Loss: -0.4312, Discriminator Loss: -0.0765, Corr Loss: 3.7364\n",
      "epoch!174\n",
      "Epoch 174 - Generator Loss: -0.4371, Discriminator Loss: -0.0764, Corr Loss: 3.5598\n",
      "epoch!175\n",
      "Epoch 175 - Generator Loss: -0.4533, Discriminator Loss: -0.0587, Corr Loss: 3.4754\n",
      "epoch!176\n",
      "Epoch 176 - Generator Loss: -0.4595, Discriminator Loss: -0.0761, Corr Loss: 3.4498\n",
      "epoch!177\n",
      "Epoch 177 - Generator Loss: -0.4552, Discriminator Loss: -0.0636, Corr Loss: 3.2270\n",
      "epoch!178\n",
      "Epoch 178 - Generator Loss: -0.4429, Discriminator Loss: -0.0716, Corr Loss: 3.3695\n",
      "epoch!179\n",
      "Epoch 179 - Generator Loss: -0.4428, Discriminator Loss: -0.0646, Corr Loss: 3.6208\n",
      "epoch!180\n",
      "Epoch 180 - Generator Loss: -0.4574, Discriminator Loss: -0.0766, Corr Loss: 3.4263\n",
      "epoch!181\n",
      "Epoch 181 - Generator Loss: -0.4121, Discriminator Loss: -0.0822, Corr Loss: 3.6755\n",
      "epoch!182\n",
      "Epoch 182 - Generator Loss: -0.4717, Discriminator Loss: -0.0722, Corr Loss: 3.3554\n",
      "epoch!183\n",
      "Epoch 183 - Generator Loss: -0.4627, Discriminator Loss: -0.0783, Corr Loss: 3.4943\n",
      "epoch!184\n",
      "Epoch 184 - Generator Loss: -0.4991, Discriminator Loss: -0.0772, Corr Loss: 3.8468\n",
      "epoch!185\n",
      "Epoch 185 - Generator Loss: -0.5039, Discriminator Loss: -0.0787, Corr Loss: 3.2389\n",
      "epoch!186\n",
      "Epoch 186 - Generator Loss: -0.4819, Discriminator Loss: -0.0816, Corr Loss: 3.6921\n",
      "epoch!187\n",
      "Epoch 187 - Generator Loss: -0.5116, Discriminator Loss: -0.0714, Corr Loss: 3.7428\n",
      "epoch!188\n",
      "Epoch 188 - Generator Loss: -0.4686, Discriminator Loss: -0.0823, Corr Loss: 3.4702\n",
      "epoch!189\n",
      "Epoch 189 - Generator Loss: -0.4779, Discriminator Loss: -0.0695, Corr Loss: 3.4425\n",
      "epoch!190\n",
      "Epoch 190 - Generator Loss: -0.4752, Discriminator Loss: -0.0770, Corr Loss: 3.5408\n",
      "epoch!191\n",
      "Epoch 191 - Generator Loss: -0.4530, Discriminator Loss: -0.0761, Corr Loss: 3.5661\n",
      "epoch!192\n",
      "Epoch 192 - Generator Loss: -0.4889, Discriminator Loss: -0.0662, Corr Loss: 3.2445\n",
      "epoch!193\n",
      "Epoch 193 - Generator Loss: -0.4857, Discriminator Loss: -0.0855, Corr Loss: 3.7317\n",
      "epoch!194\n",
      "Epoch 194 - Generator Loss: -0.4502, Discriminator Loss: -0.0858, Corr Loss: 3.5827\n",
      "epoch!195\n",
      "Epoch 195 - Generator Loss: -0.4838, Discriminator Loss: -0.0636, Corr Loss: 3.6323\n",
      "epoch!196\n",
      "Epoch 196 - Generator Loss: -0.4776, Discriminator Loss: -0.0501, Corr Loss: 3.4897\n",
      "epoch!197\n",
      "Epoch 197 - Generator Loss: -0.4793, Discriminator Loss: -0.0634, Corr Loss: 3.3547\n",
      "epoch!198\n",
      "Epoch 198 - Generator Loss: -0.4913, Discriminator Loss: -0.0525, Corr Loss: 3.6170\n",
      "epoch!199\n",
      "Epoch 199 - Generator Loss: -0.4949, Discriminator Loss: -0.0666, Corr Loss: 3.7499\n",
      "Loss convergence plot saved to C:/Users/26332/pic/loss_convergence.png\n"
     ]
    }
   ],
   "source": [
    "from ctgan import CTGAN,EnhancedCTGAN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Any, List\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#real_path = \"G:/DataSets/Churn.csv\"\n",
    "# real_path = \"G:/DataSets/newadu-20k.csv\"\n",
    "# real_path = 'G:/DataSets/adult_processed_0.csv'\n",
    "real_path = \"../CTAB-GAN-main/Real_Datasets/Adult3.csv\"\n",
    "#real_path = \"../CTAB-GAN-main/Real_Datasets/Credit.csv\"\n",
    "#real_path = '../CTGAN-main/CTGAN-main/examples/csv/train_clean.csv'\n",
    "#real_path = r\"C:\\Users\\26332\\Desktop\\Churn_Modelling_processed.csv\"\n",
    "#real_path = \"../synthcity-main/tutorials/covertype_preprocessed.csv\"\n",
    "#real_path = 'G:\\DataSets\\Covertype30k.csv'\n",
    "#real_path = \"G:/DataSets/Credit10k.csv\"\n",
    "data = pd.read_csv(real_path)\n",
    "\n",
    "discrete_columns = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if len(data[col].unique()) < 25:\n",
    "        discrete_columns.append(col)\n",
    "print(discrete_columns)\n",
    "ctgan = EnhancedCTGAN(epochs=200)\n",
    "ctgan.fit(data,discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "synthetic_data = ctgan.sample(10000)\n",
    "# print(synthetic_data)\n",
    "synthetic_data.to_csv('G:/DataSets/Fake_Dataset/2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "# stdlib\n",
    "from typing import Any, List\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ctgan import CTGAN,EnhancedCTGAN\n",
    "from torch.nn import TransformerEncoder\n",
    "# synthcity absolute\n",
    "from synthcity.plugins.core.dataloader import DataLoader, GenericDataLoader\n",
    "from synthcity.plugins.core.distribution import Distribution\n",
    "from synthcity.plugins.core.plugin import Plugin\n",
    "from synthcity.plugins.core.schema import Schema\n",
    "from synthcity.plugins.core.distribution import (\n",
    "    Distribution,\n",
    "    IntegerDistribution,\n",
    ")\n",
    "\n",
    "\n",
    "class sdv_ctgan_plugin(Plugin):\n",
    "    \"\"\"SDV CTGAN integration in synthcity.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_n_units: int = 128,\n",
    "        epochs: int = 150,\n",
    "        batch_size: int = 100,\n",
    "        cat_limit: int = 25,\n",
    "        dropout = 0.1,\n",
    "        num_first =True,\n",
    "        batch_first =True,\n",
    "        num_layers = 2,\n",
    "        num_heads = 4,\n",
    "        hidden_dim = 256,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.cat_limit = cat_limit\n",
    "        self.model = EnhancedCTGAN(\n",
    "            embedding_dim=embedding_n_units,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=False,\n",
    "            dropout = dropout,\n",
    "            num_first = num_first,\n",
    "            batch_first = batch_first,\n",
    "            num_layers = num_layers,\n",
    "            num_heads = num_heads,\n",
    "            hidden_dim = hidden_dim\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def name() -> str:\n",
    "        return \"trans_ctgan\"\n",
    "\n",
    "    @staticmethod\n",
    "    def type() -> str:\n",
    "        return \"debug\"\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperparameter_space(**kwargs: Any) -> List[Distribution]:\n",
    "        \"\"\"\n",
    "        We can customize the hyperparameter space, and use it in AutoML benchmarks.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            IntegerDistribution(name=\"embedding_n_units\", low=100, high=500, step=50),\n",
    "            IntegerDistribution(name=\"batch_size\", low=100, high=300, step=50),\n",
    "            IntegerDistribution(name=\"n_iter\", low=100, high=500, step=50),\n",
    "        ]\n",
    "\n",
    "    def _fit(self, X: DataLoader, *args: Any, **kwargs: Any) -> \"sdvPlugin\":\n",
    "        \"\"\"We selected the discrete columns based on the count of unique values, and train the CTGAN\"\"\"\n",
    "        discrete_columns = []\n",
    "\n",
    "        for col in X.columns:\n",
    "            if len(X[col].unique()) < self.cat_limit:\n",
    "                discrete_columns.append(col)\n",
    "        from torch.nn import TransformerEncoder\n",
    "        self.model.fit(X.dataframe(), discrete_columns=discrete_columns)\n",
    "        return self\n",
    "\n",
    "    def _generate(self, count: int, syn_schema: Schema, **kwargs: Any) -> pd.DataFrame:\n",
    "        return self._safe_generate(self.model.sample, count, syn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-20T09:48:17.305505+0800][22344][CRITICAL] module disabled: e:\\qycache\\anaconda\\envs\\LLM\\lib\\site-packages\\synthcity\\plugins\\generic\\plugin_goggle.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bayesian_network',\n",
       " 'image_cgan',\n",
       " 'adsgan',\n",
       " 'image_adsgan',\n",
       " 'ddpm',\n",
       " 'tvae',\n",
       " 'arf',\n",
       " 'aim',\n",
       " 'rtvae',\n",
       " 'timegan',\n",
       " 'privbayes',\n",
       " 'decaf',\n",
       " 'dpgan',\n",
       " 'pategan',\n",
       " 'survae',\n",
       " 'timevae',\n",
       " 'dummy_sampler',\n",
       " 'ctgan',\n",
       " 'uniform_sampler',\n",
       " 'marginal_distributions',\n",
       " 'nflow',\n",
       " 'survival_nflow',\n",
       " 'great',\n",
       " 'fflows',\n",
       " 'survival_ctgan',\n",
       " 'survival_gan',\n",
       " 'radialgan']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synthcity absolute\n",
    "from synthcity.plugins import Plugins\n",
    "\n",
    "generators = Plugins()\n",
    "\n",
    "generators.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bayesian_network',\n",
       " 'image_cgan',\n",
       " 'adsgan',\n",
       " 'image_adsgan',\n",
       " 'ddpm',\n",
       " 'tvae',\n",
       " 'arf',\n",
       " 'aim',\n",
       " 'rtvae',\n",
       " 'timegan',\n",
       " 'privbayes',\n",
       " 'decaf',\n",
       " 'dpgan',\n",
       " 'pategan',\n",
       " 'survae',\n",
       " 'trans_ctgan',\n",
       " 'timevae',\n",
       " 'dummy_sampler',\n",
       " 'ctgan',\n",
       " 'uniform_sampler',\n",
       " 'marginal_distributions',\n",
       " 'nflow',\n",
       " 'survival_nflow',\n",
       " 'great',\n",
       " 'fflows',\n",
       " 'survival_ctgan',\n",
       " 'survival_gan',\n",
       " 'radialgan']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generators.add(\"trans_ctgan\", sdv_ctgan_plugin)\n",
    "\n",
    "generators.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer,load_diabetes\n",
    "#X, y = load_diabetes(return_X_y=True, as_frame=True)\n",
    "#real_path = \"../CTAB-GAN-main/Real_Datasets/Adult1.csv\"\n",
    "#real_path = \"../CTAB-GAN-main/Real_Datasets/Adult3.csv\"\n",
    "real_path = \"../CTAB-GAN-main/Real_Datasets/CreditLong2.csv\"\n",
    "#real_path = '../CTGAN-main/CTGAN-main/examples/csv/train_clean.csv'\n",
    "#real_path = r\"C:\\Users\\26332\\Desktop\\Churn_Modelling_processed.csv\"\n",
    "#real_path = \"../synthcity-main/tutorials/covertype_preprocessed.csv\"\n",
    "#real_path = \"../CTAB-GAN-main/Real_Datasets/Credit.csv\"\n",
    "data = pd.read_csv(real_path)\n",
    "#data = pd.read_csv('../CTGAN-main/CTGAN-main/examples/csv/train_clean.csv')\n",
    "#data = pd.read_csv('../CTGAN-main/CTGAN-main/Adult_datasets.csv')\n",
    "loader = GenericDataLoader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n",
      "Hype-parameter:[dropout:0.3,num_first:True,batch_first:True,num_heads:2,num_layers:1,hidden_dim:256]\n",
      "epoch~0\n",
      "Epoch 0 - Generator Loss: -0.4421, Discriminator Loss: 0.2883, Corr Loss: 0.0000\n",
      "epoch~1\n",
      "Epoch 1 - Generator Loss: -0.8806, Discriminator Loss: 0.5635, Corr Loss: 0.0000\n",
      "epoch~2\n",
      "Epoch 2 - Generator Loss: -0.5152, Discriminator Loss: 0.0166, Corr Loss: 0.0000\n",
      "epoch~3\n",
      "Epoch 3 - Generator Loss: -0.5516, Discriminator Loss: 0.0636, Corr Loss: 0.0000\n",
      "epoch~4\n",
      "Epoch 4 - Generator Loss: -0.4809, Discriminator Loss: -0.0237, Corr Loss: 0.0000\n",
      "epoch~5\n",
      "Epoch 5 - Generator Loss: -0.5647, Discriminator Loss: 0.1742, Corr Loss: 0.0000\n",
      "epoch~6\n",
      "Epoch 6 - Generator Loss: -0.5227, Discriminator Loss: 0.0385, Corr Loss: 0.0000\n",
      "epoch~7\n",
      "Epoch 7 - Generator Loss: -1.0000, Discriminator Loss: -0.0000, Corr Loss: 0.0000\n",
      "epoch~8\n",
      "Epoch 8 - Generator Loss: -1.0000, Discriminator Loss: 0.0302, Corr Loss: 0.0000\n",
      "epoch~9\n",
      "Epoch 9 - Generator Loss: -0.5088, Discriminator Loss: 0.0416, Corr Loss: 0.0000\n",
      "epoch~10\n",
      "Epoch 10 - Generator Loss: -0.6468, Discriminator Loss: -0.0578, Corr Loss: 0.0000\n",
      "epoch~11\n",
      "Epoch 11 - Generator Loss: -0.9969, Discriminator Loss: 0.3780, Corr Loss: 0.0000\n",
      "epoch~12\n",
      "Epoch 12 - Generator Loss: -0.5007, Discriminator Loss: 0.0242, Corr Loss: 0.0000\n",
      "epoch~13\n",
      "Epoch 13 - Generator Loss: -1.0000, Discriminator Loss: 0.0256, Corr Loss: 0.0000\n",
      "epoch~14\n",
      "Epoch 14 - Generator Loss: -0.5335, Discriminator Loss: 0.0029, Corr Loss: 0.0000\n",
      "epoch~15\n",
      "Epoch 15 - Generator Loss: -0.6528, Discriminator Loss: -0.0257, Corr Loss: 0.0000\n",
      "epoch~16\n",
      "Epoch 16 - Generator Loss: -0.5339, Discriminator Loss: 0.0022, Corr Loss: 0.0000\n",
      "epoch~17\n",
      "Epoch 17 - Generator Loss: -0.5007, Discriminator Loss: 0.0095, Corr Loss: 0.0000\n",
      "epoch~18\n",
      "Epoch 18 - Generator Loss: -0.4949, Discriminator Loss: -0.0294, Corr Loss: 0.0000\n",
      "epoch~19\n",
      "Epoch 19 - Generator Loss: -0.5277, Discriminator Loss: 0.0151, Corr Loss: 0.0000\n",
      "epoch~20\n",
      "Epoch 20 - Generator Loss: -0.7435, Discriminator Loss: -0.0069, Corr Loss: 0.0000\n",
      "epoch~21\n",
      "Epoch 21 - Generator Loss: -0.5434, Discriminator Loss: -0.0057, Corr Loss: 0.0000\n",
      "epoch~22\n",
      "Epoch 22 - Generator Loss: -0.5887, Discriminator Loss: -0.0238, Corr Loss: 0.0000\n",
      "epoch~23\n",
      "Epoch 23 - Generator Loss: -0.4789, Discriminator Loss: 0.0214, Corr Loss: 0.0000\n",
      "epoch~24\n",
      "Epoch 24 - Generator Loss: -0.5403, Discriminator Loss: -0.0398, Corr Loss: 0.0000\n",
      "epoch~25\n",
      "Epoch 25 - Generator Loss: -0.5192, Discriminator Loss: -0.0594, Corr Loss: 0.0000\n",
      "epoch~26\n",
      "Epoch 26 - Generator Loss: -0.5454, Discriminator Loss: 0.0073, Corr Loss: 0.0000\n",
      "epoch~27\n",
      "Epoch 27 - Generator Loss: -0.4705, Discriminator Loss: -0.0174, Corr Loss: 0.0000\n",
      "epoch~28\n",
      "Epoch 28 - Generator Loss: -0.7093, Discriminator Loss: 0.0074, Corr Loss: 0.0000\n",
      "epoch~29\n",
      "Epoch 29 - Generator Loss: -0.5300, Discriminator Loss: 0.0039, Corr Loss: 0.0000\n",
      "epoch~30\n",
      "Epoch 30 - Generator Loss: -0.5927, Discriminator Loss: -0.0388, Corr Loss: 0.0000\n",
      "epoch~31\n",
      "Epoch 31 - Generator Loss: -0.4569, Discriminator Loss: -0.0153, Corr Loss: 0.0000\n",
      "epoch~32\n",
      "Epoch 32 - Generator Loss: -0.4691, Discriminator Loss: -0.0316, Corr Loss: 0.0000\n",
      "epoch~33\n",
      "Epoch 33 - Generator Loss: -0.5298, Discriminator Loss: 0.0255, Corr Loss: 0.0000\n",
      "epoch~34\n",
      "Epoch 34 - Generator Loss: -0.4768, Discriminator Loss: -0.0335, Corr Loss: 0.0000\n",
      "epoch~35\n",
      "Epoch 35 - Generator Loss: -0.5137, Discriminator Loss: -0.0034, Corr Loss: 0.0000\n",
      "epoch~36\n",
      "Epoch 36 - Generator Loss: -0.4675, Discriminator Loss: -0.0431, Corr Loss: 0.0000\n",
      "epoch~37\n",
      "Epoch 37 - Generator Loss: -0.4733, Discriminator Loss: -0.0503, Corr Loss: 0.0000\n",
      "epoch~38\n",
      "Epoch 38 - Generator Loss: -0.4835, Discriminator Loss: -0.0541, Corr Loss: 0.0000\n",
      "epoch~39\n",
      "Epoch 39 - Generator Loss: -0.5539, Discriminator Loss: -0.0765, Corr Loss: 0.0000\n",
      "epoch~40\n",
      "Epoch 40 - Generator Loss: -0.3757, Discriminator Loss: 0.0088, Corr Loss: 0.0000\n",
      "epoch~41\n",
      "Epoch 41 - Generator Loss: -0.5871, Discriminator Loss: -0.0218, Corr Loss: 0.0000\n",
      "epoch~42\n",
      "Epoch 42 - Generator Loss: -0.3710, Discriminator Loss: -0.1225, Corr Loss: 0.0000\n",
      "epoch~43\n",
      "Epoch 43 - Generator Loss: -0.3976, Discriminator Loss: -0.0518, Corr Loss: 0.0000\n",
      "epoch~44\n",
      "Epoch 44 - Generator Loss: -0.5523, Discriminator Loss: -0.1218, Corr Loss: 0.0000\n",
      "epoch~45\n",
      "Epoch 45 - Generator Loss: -0.4279, Discriminator Loss: -0.0297, Corr Loss: 0.0000\n",
      "epoch~46\n",
      "Epoch 46 - Generator Loss: -0.2946, Discriminator Loss: -0.1518, Corr Loss: 0.0000\n",
      "epoch~47\n",
      "Epoch 47 - Generator Loss: -0.3984, Discriminator Loss: -0.1249, Corr Loss: 0.0000\n",
      "epoch~48\n",
      "Epoch 48 - Generator Loss: -0.5947, Discriminator Loss: -0.0608, Corr Loss: 0.0000\n",
      "epoch~49\n",
      "Epoch 49 - Generator Loss: -0.4925, Discriminator Loss: -0.1382, Corr Loss: 0.0000\n",
      "epoch~50\n",
      "Epoch 50 - Generator Loss: -0.3945, Discriminator Loss: -0.1432, Corr Loss: 15.5949\n",
      "epoch~51\n",
      "Epoch 51 - Generator Loss: -0.4518, Discriminator Loss: -0.1480, Corr Loss: 14.4243\n",
      "epoch~52\n",
      "Epoch 52 - Generator Loss: -0.4624, Discriminator Loss: -0.2111, Corr Loss: 13.5706\n",
      "epoch~53\n",
      "Epoch 53 - Generator Loss: -0.4538, Discriminator Loss: -0.1572, Corr Loss: 13.3005\n",
      "epoch~54\n",
      "Epoch 54 - Generator Loss: -0.3867, Discriminator Loss: -0.1884, Corr Loss: 13.3534\n",
      "epoch~55\n",
      "Epoch 55 - Generator Loss: -0.5238, Discriminator Loss: -0.2190, Corr Loss: 15.3362\n",
      "epoch~56\n",
      "Epoch 56 - Generator Loss: -0.4041, Discriminator Loss: -0.1763, Corr Loss: 14.2123\n",
      "epoch~57\n",
      "Epoch 57 - Generator Loss: -0.4245, Discriminator Loss: -0.1742, Corr Loss: 15.4263\n",
      "epoch~58\n",
      "Epoch 58 - Generator Loss: -0.4446, Discriminator Loss: -0.1663, Corr Loss: 12.8555\n",
      "epoch~59\n",
      "Epoch 59 - Generator Loss: -0.3661, Discriminator Loss: -0.1640, Corr Loss: 14.0943\n",
      "epoch~60\n",
      "Epoch 60 - Generator Loss: -0.5278, Discriminator Loss: -0.2054, Corr Loss: 14.5013\n",
      "epoch~61\n",
      "Epoch 61 - Generator Loss: -0.4084, Discriminator Loss: -0.2074, Corr Loss: 13.8045\n",
      "epoch~62\n",
      "Epoch 62 - Generator Loss: -0.3170, Discriminator Loss: -0.2147, Corr Loss: 12.8905\n",
      "epoch~63\n",
      "Epoch 63 - Generator Loss: -0.4635, Discriminator Loss: -0.1928, Corr Loss: 14.2636\n",
      "epoch~64\n",
      "Epoch 64 - Generator Loss: -0.3568, Discriminator Loss: -0.2287, Corr Loss: 14.4454\n",
      "epoch~65\n",
      "Epoch 65 - Generator Loss: -0.3956, Discriminator Loss: -0.2462, Corr Loss: 13.4946\n",
      "epoch~66\n",
      "Epoch 66 - Generator Loss: -0.2964, Discriminator Loss: -0.2118, Corr Loss: 13.1976\n",
      "epoch~67\n",
      "Epoch 67 - Generator Loss: -0.4470, Discriminator Loss: -0.2380, Corr Loss: 14.4196\n",
      "epoch~68\n",
      "Epoch 68 - Generator Loss: -0.3677, Discriminator Loss: -0.1894, Corr Loss: 13.5715\n",
      "epoch~69\n",
      "Epoch 69 - Generator Loss: -0.3810, Discriminator Loss: -0.1908, Corr Loss: 14.0611\n",
      "epoch~70\n",
      "Epoch 70 - Generator Loss: -0.2732, Discriminator Loss: -0.2494, Corr Loss: 14.0595\n",
      "epoch~71\n",
      "Epoch 71 - Generator Loss: -0.4194, Discriminator Loss: -0.2629, Corr Loss: 14.0124\n",
      "epoch~72\n",
      "Epoch 72 - Generator Loss: -0.4804, Discriminator Loss: -0.2352, Corr Loss: 12.5406\n",
      "epoch~73\n",
      "Epoch 73 - Generator Loss: -0.4532, Discriminator Loss: -0.1432, Corr Loss: 13.1239\n",
      "epoch~74\n",
      "Epoch 74 - Generator Loss: -0.5018, Discriminator Loss: -0.2218, Corr Loss: 14.2015\n",
      "epoch~75\n",
      "Epoch 75 - Generator Loss: -0.3997, Discriminator Loss: -0.2310, Corr Loss: 15.1708\n",
      "epoch~76\n",
      "Epoch 76 - Generator Loss: -0.4139, Discriminator Loss: -0.1859, Corr Loss: 12.9603\n",
      "epoch~77\n",
      "Epoch 77 - Generator Loss: -0.4264, Discriminator Loss: -0.2158, Corr Loss: 14.9433\n",
      "epoch~78\n",
      "Epoch 78 - Generator Loss: -0.3906, Discriminator Loss: -0.2336, Corr Loss: 14.5763\n",
      "epoch~79\n",
      "Epoch 79 - Generator Loss: -0.3460, Discriminator Loss: -0.2364, Corr Loss: 12.7417\n",
      "epoch~80\n",
      "Epoch 80 - Generator Loss: -0.4640, Discriminator Loss: -0.1930, Corr Loss: 14.1931\n",
      "epoch~81\n",
      "Epoch 81 - Generator Loss: -0.3979, Discriminator Loss: -0.2188, Corr Loss: 15.3387\n",
      "epoch~82\n",
      "Epoch 82 - Generator Loss: -0.3636, Discriminator Loss: -0.2153, Corr Loss: 15.2907\n",
      "epoch~83\n",
      "Epoch 83 - Generator Loss: -0.3830, Discriminator Loss: -0.2405, Corr Loss: 12.2037\n",
      "epoch~84\n",
      "Epoch 84 - Generator Loss: -0.4120, Discriminator Loss: -0.2462, Corr Loss: 13.5488\n",
      "epoch~85\n",
      "Epoch 85 - Generator Loss: -0.3456, Discriminator Loss: -0.2797, Corr Loss: 13.1910\n",
      "epoch~86\n",
      "Epoch 86 - Generator Loss: -0.4753, Discriminator Loss: -0.2225, Corr Loss: 15.3287\n",
      "epoch~87\n",
      "Epoch 87 - Generator Loss: -0.4231, Discriminator Loss: -0.2632, Corr Loss: 12.5730\n",
      "epoch~88\n",
      "Epoch 88 - Generator Loss: -0.3539, Discriminator Loss: -0.2546, Corr Loss: 14.5923\n",
      "epoch~89\n",
      "Epoch 89 - Generator Loss: -0.3261, Discriminator Loss: -0.2778, Corr Loss: 14.1060\n",
      "epoch~90\n",
      "Epoch 90 - Generator Loss: -0.4063, Discriminator Loss: -0.2391, Corr Loss: 12.4371\n",
      "epoch~91\n",
      "Epoch 91 - Generator Loss: -0.3810, Discriminator Loss: -0.2723, Corr Loss: 14.3764\n",
      "epoch~92\n",
      "Epoch 92 - Generator Loss: -0.3733, Discriminator Loss: -0.2426, Corr Loss: 13.7987\n",
      "epoch~93\n",
      "Epoch 93 - Generator Loss: -0.3891, Discriminator Loss: -0.2188, Corr Loss: 14.3965\n",
      "epoch~94\n",
      "Epoch 94 - Generator Loss: -0.3385, Discriminator Loss: -0.2812, Corr Loss: 12.5361\n",
      "epoch~95\n",
      "Epoch 95 - Generator Loss: -0.4426, Discriminator Loss: -0.2559, Corr Loss: 12.5864\n",
      "epoch~96\n",
      "Epoch 96 - Generator Loss: -0.4488, Discriminator Loss: -0.2647, Corr Loss: 13.3173\n",
      "epoch~97\n",
      "Epoch 97 - Generator Loss: -0.3863, Discriminator Loss: -0.2385, Corr Loss: 12.7321\n",
      "epoch~98\n",
      "Epoch 98 - Generator Loss: -0.3913, Discriminator Loss: -0.2464, Corr Loss: 14.4494\n",
      "epoch~99\n",
      "Epoch 99 - Generator Loss: -0.4071, Discriminator Loss: -0.2471, Corr Loss: 14.1664\n",
      "epoch~100\n",
      "Epoch 100 - Generator Loss: -0.4060, Discriminator Loss: -0.2270, Corr Loss: 13.4191\n",
      "epoch~101\n",
      "Epoch 101 - Generator Loss: -0.4057, Discriminator Loss: -0.2671, Corr Loss: 15.3277\n",
      "epoch~102\n",
      "Epoch 102 - Generator Loss: -0.3668, Discriminator Loss: -0.2592, Corr Loss: 13.2120\n",
      "epoch~103\n",
      "Epoch 103 - Generator Loss: -0.3450, Discriminator Loss: -0.2089, Corr Loss: 13.0731\n",
      "epoch~104\n",
      "Epoch 104 - Generator Loss: -0.3610, Discriminator Loss: -0.2259, Corr Loss: 14.7394\n",
      "epoch~105\n",
      "Epoch 105 - Generator Loss: -0.4240, Discriminator Loss: -0.2206, Corr Loss: 14.7915\n",
      "epoch~106\n",
      "Epoch 106 - Generator Loss: -0.3981, Discriminator Loss: -0.2334, Corr Loss: 12.7028\n",
      "epoch~107\n",
      "Epoch 107 - Generator Loss: -0.3657, Discriminator Loss: -0.2250, Corr Loss: 11.3357\n",
      "epoch~108\n",
      "Epoch 108 - Generator Loss: -0.4304, Discriminator Loss: -0.2648, Corr Loss: 13.7239\n",
      "epoch~109\n",
      "Epoch 109 - Generator Loss: -0.4116, Discriminator Loss: -0.2646, Corr Loss: 12.6389\n",
      "epoch~110\n",
      "Epoch 110 - Generator Loss: -0.3471, Discriminator Loss: -0.2532, Corr Loss: 14.6012\n",
      "epoch~111\n",
      "Epoch 111 - Generator Loss: -0.4057, Discriminator Loss: -0.2583, Corr Loss: 15.5843\n",
      "epoch~112\n",
      "Epoch 112 - Generator Loss: -0.4004, Discriminator Loss: -0.2687, Corr Loss: 13.0996\n",
      "epoch~113\n",
      "Epoch 113 - Generator Loss: -0.3025, Discriminator Loss: -0.2691, Corr Loss: 15.3266\n",
      "epoch~114\n",
      "Epoch 114 - Generator Loss: -0.3275, Discriminator Loss: -0.2879, Corr Loss: 16.9017\n",
      "epoch~115\n",
      "Epoch 115 - Generator Loss: -0.3219, Discriminator Loss: -0.2438, Corr Loss: 12.1677\n",
      "epoch~116\n",
      "Epoch 116 - Generator Loss: -0.4422, Discriminator Loss: -0.2046, Corr Loss: 13.3536\n",
      "epoch~117\n",
      "Epoch 117 - Generator Loss: -0.4013, Discriminator Loss: -0.2697, Corr Loss: 14.4518\n",
      "epoch~118\n",
      "Epoch 118 - Generator Loss: -0.4146, Discriminator Loss: -0.2471, Corr Loss: 14.2887\n",
      "epoch~119\n",
      "Epoch 119 - Generator Loss: -0.3356, Discriminator Loss: -0.2774, Corr Loss: 16.0339\n",
      "epoch~120\n",
      "Epoch 120 - Generator Loss: -0.4222, Discriminator Loss: -0.2710, Corr Loss: 12.5461\n",
      "epoch~121\n",
      "Epoch 121 - Generator Loss: -0.2523, Discriminator Loss: -0.2595, Corr Loss: 15.3059\n",
      "epoch~122\n",
      "Epoch 122 - Generator Loss: -0.4068, Discriminator Loss: -0.2401, Corr Loss: 12.3644\n",
      "epoch~123\n",
      "Epoch 123 - Generator Loss: -0.4275, Discriminator Loss: -0.2863, Corr Loss: 15.5199\n",
      "epoch~124\n",
      "Epoch 124 - Generator Loss: -0.4179, Discriminator Loss: -0.2622, Corr Loss: 13.2126\n",
      "epoch~125\n",
      "Epoch 125 - Generator Loss: -0.4021, Discriminator Loss: -0.2479, Corr Loss: 14.5410\n",
      "epoch~126\n",
      "Epoch 126 - Generator Loss: -0.4361, Discriminator Loss: -0.2653, Corr Loss: 12.8030\n",
      "epoch~127\n",
      "Epoch 127 - Generator Loss: -0.4236, Discriminator Loss: -0.2655, Corr Loss: 13.8326\n",
      "epoch~128\n",
      "Epoch 128 - Generator Loss: -0.3236, Discriminator Loss: -0.3052, Corr Loss: 16.2270\n",
      "epoch~129\n",
      "Epoch 129 - Generator Loss: -0.3666, Discriminator Loss: -0.2717, Corr Loss: 13.8728\n",
      "epoch~130\n",
      "Epoch 130 - Generator Loss: -0.2577, Discriminator Loss: -0.2627, Corr Loss: 15.6130\n",
      "epoch~131\n",
      "Epoch 131 - Generator Loss: -0.3670, Discriminator Loss: -0.2617, Corr Loss: 12.1779\n",
      "epoch~132\n",
      "Epoch 132 - Generator Loss: -0.4188, Discriminator Loss: -0.2691, Corr Loss: 14.0794\n",
      "epoch~133\n",
      "Epoch 133 - Generator Loss: -0.4865, Discriminator Loss: -0.2486, Corr Loss: 15.5785\n",
      "epoch~134\n",
      "Epoch 134 - Generator Loss: -0.3502, Discriminator Loss: -0.2952, Corr Loss: 13.4117\n",
      "epoch~135\n",
      "Epoch 135 - Generator Loss: -0.4244, Discriminator Loss: -0.2888, Corr Loss: 11.0782\n",
      "epoch~136\n",
      "Epoch 136 - Generator Loss: -0.3795, Discriminator Loss: -0.2674, Corr Loss: 15.1912\n",
      "epoch~137\n",
      "Epoch 137 - Generator Loss: -0.3439, Discriminator Loss: -0.2464, Corr Loss: 13.8972\n",
      "epoch~138\n",
      "Epoch 138 - Generator Loss: -0.3421, Discriminator Loss: -0.2601, Corr Loss: 13.0145\n",
      "epoch~139\n",
      "Epoch 139 - Generator Loss: -0.3825, Discriminator Loss: -0.2871, Corr Loss: 15.3702\n",
      "epoch~140\n",
      "Epoch 140 - Generator Loss: -0.3605, Discriminator Loss: -0.2297, Corr Loss: 15.5061\n",
      "epoch~141\n",
      "Epoch 141 - Generator Loss: -0.3895, Discriminator Loss: -0.3085, Corr Loss: 15.4685\n",
      "epoch~142\n",
      "Epoch 142 - Generator Loss: -0.4480, Discriminator Loss: -0.3112, Corr Loss: 14.1322\n",
      "epoch~143\n",
      "Epoch 143 - Generator Loss: -0.3803, Discriminator Loss: -0.2401, Corr Loss: 13.6939\n",
      "epoch~144\n",
      "Epoch 144 - Generator Loss: -0.3361, Discriminator Loss: -0.2755, Corr Loss: 13.5347\n",
      "epoch~145\n",
      "Epoch 145 - Generator Loss: -0.3854, Discriminator Loss: -0.3009, Corr Loss: 15.1696\n",
      "epoch~146\n",
      "Epoch 146 - Generator Loss: -0.2307, Discriminator Loss: -0.2675, Corr Loss: 14.9584\n",
      "epoch~147\n",
      "Epoch 147 - Generator Loss: -0.3392, Discriminator Loss: -0.3396, Corr Loss: 14.1759\n",
      "epoch~148\n",
      "Epoch 148 - Generator Loss: -0.3364, Discriminator Loss: -0.2853, Corr Loss: 15.8049\n",
      "epoch~149\n",
      "Epoch 149 - Generator Loss: -0.2271, Discriminator Loss: -0.2636, Corr Loss: 11.8030\n",
      "epoch~150\n",
      "Epoch 150 - Generator Loss: -0.3031, Discriminator Loss: -0.2516, Corr Loss: 13.4686\n",
      "epoch~151\n",
      "Epoch 151 - Generator Loss: -0.3886, Discriminator Loss: -0.2786, Corr Loss: 12.8997\n",
      "epoch~152\n",
      "Epoch 152 - Generator Loss: -0.2395, Discriminator Loss: -0.2132, Corr Loss: 14.8794\n",
      "epoch~153\n",
      "Epoch 153 - Generator Loss: -0.3374, Discriminator Loss: -0.3148, Corr Loss: 12.8123\n",
      "epoch~154\n",
      "Epoch 154 - Generator Loss: -0.3414, Discriminator Loss: -0.3053, Corr Loss: 13.5736\n",
      "epoch~155\n",
      "Epoch 155 - Generator Loss: -0.2339, Discriminator Loss: -0.2962, Corr Loss: 13.9527\n",
      "epoch~156\n",
      "Epoch 156 - Generator Loss: -0.2993, Discriminator Loss: -0.3411, Corr Loss: 13.0906\n",
      "epoch~157\n",
      "Epoch 157 - Generator Loss: -0.3198, Discriminator Loss: -0.3545, Corr Loss: 15.3636\n",
      "epoch~158\n",
      "Epoch 158 - Generator Loss: -0.3061, Discriminator Loss: -0.3307, Corr Loss: 18.3401\n",
      "epoch~159\n",
      "Epoch 159 - Generator Loss: -0.2847, Discriminator Loss: -0.3253, Corr Loss: 14.8058\n",
      "epoch~160\n",
      "Epoch 160 - Generator Loss: -0.1493, Discriminator Loss: -0.2193, Corr Loss: 15.4970\n",
      "epoch~161\n",
      "Epoch 161 - Generator Loss: -0.3488, Discriminator Loss: -0.3539, Corr Loss: 12.2052\n",
      "epoch~162\n",
      "Epoch 162 - Generator Loss: -0.2589, Discriminator Loss: -0.3211, Corr Loss: 13.9082\n",
      "epoch~163\n",
      "Epoch 163 - Generator Loss: -0.2705, Discriminator Loss: -0.3588, Corr Loss: 13.1594\n",
      "epoch~164\n",
      "Epoch 164 - Generator Loss: -0.2604, Discriminator Loss: -0.3897, Corr Loss: 13.0386\n",
      "epoch~165\n",
      "Epoch 165 - Generator Loss: -0.2581, Discriminator Loss: -0.3477, Corr Loss: 13.4627\n",
      "epoch~166\n",
      "Epoch 166 - Generator Loss: -0.2573, Discriminator Loss: -0.4065, Corr Loss: 12.4581\n",
      "epoch~167\n",
      "Epoch 167 - Generator Loss: -0.2948, Discriminator Loss: -0.4244, Corr Loss: 13.1831\n",
      "epoch~168\n",
      "Epoch 168 - Generator Loss: -0.1365, Discriminator Loss: -0.4230, Corr Loss: 14.9669\n",
      "epoch~169\n",
      "Epoch 169 - Generator Loss: -0.2536, Discriminator Loss: -0.6309, Corr Loss: 12.4826\n",
      "epoch~170\n",
      "Epoch 170 - Generator Loss: -0.0739, Discriminator Loss: -0.6081, Corr Loss: 14.4482\n",
      "epoch~171\n",
      "Epoch 171 - Generator Loss: -0.0926, Discriminator Loss: -0.7873, Corr Loss: 14.6665\n",
      "epoch~172\n",
      "Epoch 172 - Generator Loss: -0.1219, Discriminator Loss: -0.5834, Corr Loss: 11.7173\n",
      "epoch~173\n",
      "Epoch 173 - Generator Loss: -0.1026, Discriminator Loss: -0.7929, Corr Loss: 14.2376\n",
      "epoch~174\n",
      "Epoch 174 - Generator Loss: -0.0955, Discriminator Loss: -0.6411, Corr Loss: 13.1774\n",
      "epoch~175\n",
      "Epoch 175 - Generator Loss: -0.0957, Discriminator Loss: -0.7229, Corr Loss: 14.7090\n",
      "epoch~176\n",
      "Epoch 176 - Generator Loss: -0.0819, Discriminator Loss: -0.7141, Corr Loss: 12.4001\n",
      "epoch~177\n",
      "Epoch 177 - Generator Loss: -0.6387, Discriminator Loss: 0.1530, Corr Loss: 19.4773\n",
      "epoch~178\n",
      "Epoch 178 - Generator Loss: -0.6899, Discriminator Loss: 0.0256, Corr Loss: 15.9659\n",
      "epoch~179\n",
      "Epoch 179 - Generator Loss: -0.5119, Discriminator Loss: -0.1231, Corr Loss: 15.1345\n",
      "epoch~180\n",
      "Epoch 180 - Generator Loss: -0.3737, Discriminator Loss: -0.1133, Corr Loss: 15.0357\n",
      "epoch~181\n",
      "Epoch 181 - Generator Loss: -0.5237, Discriminator Loss: -0.1573, Corr Loss: 13.3091\n",
      "epoch~182\n",
      "Epoch 182 - Generator Loss: -0.4019, Discriminator Loss: -0.2114, Corr Loss: 11.4477\n",
      "epoch~183\n",
      "Epoch 183 - Generator Loss: -0.4797, Discriminator Loss: -0.1839, Corr Loss: 14.8379\n",
      "epoch~184\n",
      "Epoch 184 - Generator Loss: -0.5802, Discriminator Loss: -0.1699, Corr Loss: 12.0026\n",
      "epoch~185\n",
      "Epoch 185 - Generator Loss: -0.4217, Discriminator Loss: -0.1681, Corr Loss: 13.3781\n",
      "epoch~186\n",
      "Epoch 186 - Generator Loss: -0.2887, Discriminator Loss: -0.2120, Corr Loss: 13.4178\n",
      "epoch~187\n",
      "Epoch 187 - Generator Loss: -0.3321, Discriminator Loss: -0.2230, Corr Loss: 13.2708\n",
      "epoch~188\n",
      "Epoch 188 - Generator Loss: -0.3411, Discriminator Loss: -0.1924, Corr Loss: 12.9405\n",
      "epoch~189\n",
      "Epoch 189 - Generator Loss: -0.3635, Discriminator Loss: -0.2482, Corr Loss: 11.7142\n",
      "epoch~190\n",
      "Epoch 190 - Generator Loss: -0.3856, Discriminator Loss: -0.1958, Corr Loss: 14.3913\n",
      "epoch~191\n",
      "Epoch 191 - Generator Loss: -0.3535, Discriminator Loss: -0.2926, Corr Loss: 14.2236\n",
      "epoch~192\n",
      "Epoch 192 - Generator Loss: -0.3308, Discriminator Loss: -0.3394, Corr Loss: 12.3117\n",
      "epoch~193\n",
      "Epoch 193 - Generator Loss: -0.3153, Discriminator Loss: -0.4117, Corr Loss: 12.7357\n",
      "epoch~194\n",
      "Epoch 194 - Generator Loss: -0.2791, Discriminator Loss: -0.3291, Corr Loss: 12.5936\n",
      "epoch~195\n",
      "Epoch 195 - Generator Loss: -0.2170, Discriminator Loss: -0.4708, Corr Loss: 12.3431\n",
      "epoch~196\n",
      "Epoch 196 - Generator Loss: -0.2640, Discriminator Loss: -0.2510, Corr Loss: 12.8760\n",
      "epoch~197\n",
      "Epoch 197 - Generator Loss: -0.2505, Discriminator Loss: -0.4864, Corr Loss: 13.0185\n",
      "epoch~198\n",
      "Epoch 198 - Generator Loss: -0.1679, Discriminator Loss: -0.5814, Corr Loss: 14.0350\n",
      "epoch~199\n",
      "Epoch 199 - Generator Loss: -0.2624, Discriminator Loss: -0.6080, Corr Loss: 12.9793\n",
      "Loss convergence plot saved to C:/Users/26332/pic/loss_convergence.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.sdv_ctgan_plugin at 0x1dee08178e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the new plugin\n",
    "from torch.nn import TransformerEncoder\n",
    "geng = generators.get(\"trans_ctgan\", epochs=200)\n",
    "\n",
    "geng.fit(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some new data\n",
    "d = geng.generate(count=10000).dataframe()\n",
    "d.to_csv('./duanwen-trans-cre.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix_real = data.corr()\n",
    "sns.heatmap(correlation_matrix_real, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap--Real_data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_fake = a.corr()\n",
    "sns.heatmap(correlation_matrix_fake, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap--Fake_data')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
